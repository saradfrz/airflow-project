---------
docker-compose.yaml code
----------
version: '3'

networks:
  ndsnet:
    driver: bridge

volumes:
  postgres_data:

services:
  postgres:
    image: postgres:13
    container_name: postgres
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./initdb:/docker-entrypoint-initdb.d  # Mounting init scripts directory
    networks:
      - ndsnet

  airflow-init:
    image: apache/airflow:2.10.5
    depends_on:
      - postgres
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
    volumes:
      - ./dags:/opt/airflow/dags
    command: >
      bash -c "airflow db init &&
      airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin"
    networks:
      - ndsnet

  airflow-webserver:
    image: apache/airflow:2.10.5
    depends_on:
      - airflow-init
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
    volumes:
      - ./dags:/opt/airflow/dags
    ports:
      - "8080:8080"
    command: webserver
    networks:
      - ndsnet

  airflow-scheduler:
    image: apache/airflow:2.10.5
    depends_on:
      - airflow-init
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
    volumes:
      - ./dags:/opt/airflow/dags
    command: scheduler
    networks:
      - ndsnet

  superset:
    image: apache/superset:latest
    container_name: superset
    depends_on:
      - postgres
    environment:
      - SUPERSET_CONFIG_PATH=/etc/superset
      - SUPERSET_DATABASE_URL=postgresql+psycopg2://superset:superset@postgres/superset
    volumes:
      - ./superset:/etc/superset
    ports:
      - "8088:8088"
    command: >
      sh -c "superset db upgrade &&
      superset init &&
      superset fab create-admin --username admin --firstname Superset --lastname Admin --email admin@example.com --password admin"
    networks:
      - ndsnet

  minio:
    image: minio/minio:latest
    container_name: minio
    hostname: minio
    restart: always
    volumes:
      - ./include/data/minio:/data
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio123
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - ndsnet

  spark-master:
    image: bitnami/spark:latest
    container_name: spark-master
    ports:
      - "8082:8080"
      - "7077:7077"
    environment:
      - SPARK_MODE=master
    networks:
      - ndsnet

  spark-worker:
    image: bitnami/spark:latest
    container_name: spark-worker
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    networks:
      - ndsnet

  docker-proxy:
    image: alpine/socat
    command: "TCP4-LISTEN:2375,fork,reuseaddr UNIX-CONNECT:/var/run/docker.sock"
    ports:
      - "2376:2375"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - ndsnet


---------
k8s/dbt-deployment.yaml code
----------
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dbt
spec:
  replicas: 1
  selector:
    matchLabels:
      app: dbt
  template:
    metadata:
      labels:
        app: dbt
    spec:
      containers:
      - name: dbt
        image: fishtownanalytics/dbt:latest
        command: ["sleep", "infinity"]
        # Adjust the command as needed to run your dbt jobs or use a Kubernetes Job for one-off runs.


---------
k8s/dbt-service.yaml code
----------
apiVersion: v1
kind: Service
metadata:
  name: dbt
spec:
  selector:
    app: dbt
  ports:
  - port: 8082        # New external port
    targetPort: 8080  # Container's port remains unchanged
  type: ClusterIP


---------
k8s/kafka-deployment.yaml code
----------
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      containers:
      - name: kafka
        image: bitnami/kafka:latest
        ports:
        - containerPort: 9092
        env:
          - name: KAFKA_BROKER_ID
            value: "1"
          - name: KAFKA_ADVERTISED_LISTENERS
            value: "PLAINTEXT://kafka:9092"
          - name: KAFKA_LISTENERS
            value: "PLAINTEXT://0.0.0.0:9092"
---
apiVersion: v1
kind: Service
metadata:
  name: kafka
spec:
  selector:
    app: kafka
  ports:
  - port: 9092
    targetPort: 9092


---------
k8s/metabase-deployment.yaml code
----------
apiVersion: apps/v1
kind: Deployment
metadata:
  name: metabase
spec:
  replicas: 1
  selector:
    matchLabels:
      app: metabase
  template:
    metadata:
      labels:
        app: metabase
    spec:
      containers:
      - name: metabase
        image: metabase/metabase:latest
        ports:
        - containerPort: 3000
        # Add volumes or environment variables as needed
---
apiVersion: v1
kind: Service
metadata:
  name: metabase
spec:
  type: NodePort
  selector:
    app: metabase
  ports:
  - port: 3000
    targetPort: 3000
    nodePort: 30300


---------
k8s/superset-deployment.yaml code
----------
apiVersion: apps/v1
kind: Deployment
metadata:
  name: superset
spec:
  replicas: 1
  selector:
    matchLabels:
      app: superset
  template:
    metadata:
      labels:
        app: superset
    spec:
      containers:
      - name: superset
        image: apache/superset:latest
        ports:
        - containerPort: 8088
        env:
        - name: SUPERSET_ENV
          value: "production"
        - name: SUPERSET_DATABASE_URI
          value: "postgresql://superset:superset@postgres:5432/superset"
        - name: SUPERSET_CONFIG_PATH  # ✅ Explicitly set the config file path
          value: "/etc/superset/superset_config.py"
        - name: SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: superset-secret
              key: secret_key
        volumeMounts:
          - name: superset-config
            mountPath: /etc/superset  # ✅ Mounting the file
            subPath: superset_config.py  # ✅ Ensuring it's a file
      volumes:
        - name: superset-config
          configMap:
            name: superset-config
---
apiVersion: v1
kind: Service
metadata:
  name: superset
spec:
  type: NodePort
  selector:
    app: superset
  ports:
  - port: 8088
    targetPort: 8088
    protocol: TCP
    nodePort: 30088
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: superset-config
data:
  superset_config.py: |
    import os
    SQLALCHEMY_DATABASE_URI = "postgresql://superset:superset@postgres:5432/superset"
    SECRET_KEY = os.getenv("SECRET_KEY", "your_secret_key")
---
apiVersion: v1
kind: Secret
metadata:
  name: superset-secret
type: Opaque
data:
  secret_key: eW91cl9zZWNyZXRfa2V5  # Base64 encoded value of "your_secret_key"


---------
k8s/zookeeper-deployment.yaml code
----------
apiVersion: apps/v1
kind: Deployment
metadata:
  name: zookeeper
spec:
  replicas: 1
  selector:
    matchLabels:
      app: zookeeper
  template:
    metadata:
      labels:
        app: zookeeper
    spec:
      containers:
      - name: zookeeper
        image: bitnami/zookeeper:latest
        ports:
        - containerPort: 2181
        env:
          - name: ALLOW_ANONYMOUS_LOGIN
            value: "yes"
---
apiVersion: v1
kind: Service
metadata:
  name: zookeeper
spec:
  selector:
    app: zookeeper
  ports:
  - port: 2181
    targetPort: 2181


